For the backend side of this project, the Python language was used to write the code to be able to get the data needed to build the website with.  A Python library called Beautiful Soup was used to make the scraping of the webpages easier.  The data for the teams and players was found on two different websites, with team data coming from cfbdatawarehouse.com and player data coming from cfbstats.com.  A snippet of code of pulling data from cfbstats taken from stackoverflow.com was used as a basis for grabbing the player data from one player at a time and since all the data that was being scraped was in table form it was relatively easy to get to it. This code output the player’s stats for the specific year of 2014 which included their number, name, position played, year in school, height, weight, hometown, and last school played at. A dictionary was built for all teams and their specific URL unique identifier so that the URL’s could be traversed to grab all the player’s data at one time.  Having the ability to go through all the players specific URL’s enabled the implementation to be able to create a text file with all the players and their stats separated by their team names.  

After getting the text file with all the players and their individual stats, the next step was to get all the teams and their stats.  To be able to navigate through the webpages was different from cfbstats.  The pages URL unique identifier were separated first by the first letter of the team name, then they were separated by the full team name.  To handle this, the index of the first character of the string was assigned to a string which was then placed in as the first unique identifier.  For the second part of the unique identifier, the team name from the dictionary was modified to fit the input needed which was without spaces or dashes, and those were replaced by underscores.  After this was implemented all of the team pages were successfully being browsed to and then the only thing left to do was to get the stats that were wanted. To get to the data for the teams was much more tedious for this website because none of the data needed was in table form.  The source code for team webpages from cfbdatawarehouse had to be analyzed to find out where the data was located specifically and in between what tags. Once that was located, Beautiful Soup provided a very elegant way to find the surrounding tags and just pull out the data that was wanted, which was then output into a text file.  The next step for handling these data files is to output them into an object data structure such as a JSON file so that the database will be able to easily intake the data.  There are a few things that will be added in the future like the input of the coaches names and pictures as well trying to get the players other stats in regards to the gameplay.